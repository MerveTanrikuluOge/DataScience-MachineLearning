{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml # MNIST data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist.data[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1: Neural net classifier, 1 layer, 1 units\n",
      "Train score = 0.403029, Test score = 0.395029\n",
      ", loss = 1.505383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1: Neural net classifier, 1 layer, 10 units\n",
      "Train score = 0.962933, Test score = 0.932457\n",
      ", loss = 0.131018\n",
      "Dataset 1: Neural net classifier, 1 layer, 100 units\n",
      "Train score = 1.000000, Test score = 0.976286\n",
      ", loss = 0.001004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "for units in [1, 10, 100]:\n",
    "    nnclf = MLPClassifier(hidden_layer_sizes = [units], solver='adam',\n",
    "                         random_state = 0).fit(X_train, y_train)\n",
    "    train_score = nnclf.score(X_train, y_train)\n",
    "    test_score  = nnclf.score(X_test, y_test)\n",
    "    loss = nnclf.loss_\n",
    "    title = 'Dataset 1: Neural net classifier, 1 layer, {} units'.format(units)\n",
    "    print(title)\n",
    "    title2 = \"Train score = %f, Test score = %f, loss = %f\\n\" % (train_score, test_score, loss)\n",
    "    print(title2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1: Neural net classifier, 1 layer, 1 units\n",
      "Train score = 0.112495, Test score = 0.112629, loss = 2.301123\n",
      "\n",
      "Dataset 1: Neural net classifier, 1 layer, 10 units\n",
      "Train score = 0.918324, Test score = 0.903200, loss = 0.289801\n",
      "\n",
      "Dataset 1: Neural net classifier, 1 layer, 100 units\n",
      "Train score = 1.000000, Test score = 0.974457, loss = 0.000419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "for units in [1, 10, 100]:\n",
    "    nnclf = MLPClassifier(hidden_layer_sizes = [units], solver='lbfgs',\n",
    "                         random_state = 0).fit(X_train, y_train)\n",
    "    train_score = nnclf.score(X_train, y_train)\n",
    "    test_score  = nnclf.score(X_test, y_test)\n",
    "    loss = nnclf.loss_\n",
    "    title = 'Dataset 1: Neural net classifier, 1 layer, {} units'.format(units)\n",
    "    print(title)\n",
    "    title2 = \"Train score = %f, Test score = %f, loss = %f\\n\" % (train_score, test_score, loss)\n",
    "    print(title2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1: Neural net classifier, 2 layers, 10/10 units\n",
      "Train score = 0.969276, Test score = 0.933314, loss = 0.110510\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "nnclf = MLPClassifier(hidden_layer_sizes = [10, 10], solver='adam',\n",
    "                     random_state = 0).fit(X_train, y_train)\n",
    "train_score = nnclf.score(X_train, y_train)\n",
    "test_score  = nnclf.score(X_test, y_test)\n",
    "loss = nnclf.loss_\n",
    "title = 'Dataset 1: Neural net classifier, 2 layers, 10/10 units'\n",
    "print(title)\n",
    "title2 = \"Train score = %f, Test score = %f, loss = %f\\n\" % (train_score, test_score, loss)\n",
    "print(title2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1: Neural net classifier, 3 layers, 30/30/30 units\n",
      "Train score = 0.987048, Test score = 0.960457, loss = 0.043491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "nnclf = MLPClassifier(hidden_layer_sizes = [30, 30, 30], solver='lbfgs',\n",
    "                     random_state = 0).fit(X_train, y_train)\n",
    "train_score = nnclf.score(X_train, y_train)\n",
    "test_score  = nnclf.score(X_test, y_test)\n",
    "loss = nnclf.loss_\n",
    "title = 'Dataset 1: Neural net classifier, 3 layers, 30/30/30 units'\n",
    "print(title)\n",
    "title2 = \"Train score = %f, Test score = %f, loss = %f\\n\" % (train_score, test_score, loss)\n",
    "print(title2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1: Neural net classifier, 3 layers, 30/30/30 units\n",
      "Train score = 0.999448, Test score = 0.962400, loss = 0.004381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "nnclf = MLPClassifier(hidden_layer_sizes = [30, 30, 30], solver='adam',\n",
    "                     random_state = 0).fit(X_train, y_train)\n",
    "train_score = nnclf.score(X_train, y_train)\n",
    "test_score  = nnclf.score(X_test, y_test)\n",
    "loss = nnclf.loss_\n",
    "title = 'Dataset 1: Neural net classifier, 3 layers, 30/30/30 units'\n",
    "print(title)\n",
    "title2 = \"Train score = %f, Test score = %f, loss = %f\\n\" % (train_score, test_score, loss)\n",
    "print(title2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1: Neural net classifier, 2 layers, 10/10 units\n",
      "Train score = 0.922686, Test score = 0.909886, loss = 0.266652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "nnclf = MLPClassifier(hidden_layer_sizes = [10, 10], solver='lbfgs',\n",
    "                     random_state = 0).fit(X_train, y_train)\n",
    "train_score = nnclf.score(X_train, y_train)\n",
    "test_score  = nnclf.score(X_test, y_test)\n",
    "loss = nnclf.loss_\n",
    "title = 'Dataset 1: Neural net classifier, 2 layers, 10/10 units'\n",
    "print(title)\n",
    "title2 = \"Train score = %f, Test score = %f, loss = %f\\n\" % (train_score, test_score, loss)\n",
    "print(title2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 2: NN classifier, alpha = 0.010\n",
      "Train score = 0.967257, Test score = 0.935086, loss = 0.133110\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 2: NN classifier, alpha = 0.100\n",
      "Train score = 0.955676, Test score = 0.935714, loss = 0.196007\n",
      "\n",
      "Dataset 2: NN classifier, alpha = 1.000\n",
      "Train score = 0.935924, Test score = 0.928514, loss = 0.394480\n",
      "\n",
      "Dataset 2: NN classifier, alpha = 5.000\n",
      "Train score = 0.894762, Test score = 0.889029, loss = 0.833031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for this_alpha in [0.01, 0.1, 1.0, 5.0]:\n",
    "    nnclf = MLPClassifier(solver='adam', activation = 'relu',\n",
    "                         alpha = this_alpha,\n",
    "                         hidden_layer_sizes = [10, 10],\n",
    "                         random_state = 0).fit(X_train, y_train)\n",
    "    train_score = nnclf.score(X_train, y_train)\n",
    "    test_score  = nnclf.score(X_test, y_test)\n",
    "    loss = nnclf.loss_\n",
    "    title = 'Dataset 2: NN classifier, alpha = {:.3f}'.format(this_alpha)\n",
    "    print(title)\n",
    "    title2 = \"Train score = %f, Test score = %f, loss = %f\\n\" % (train_score, test_score, loss)\n",
    "    print(title2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 2: NN classifier, alpha = 0.010 \n",
      "Train score = 0.962895, Test score = 0.929657, loss = 0.136123\n",
      "\n",
      "Dataset 2: NN classifier, alpha = 0.100 \n",
      "Train score = 0.963257, Test score = 0.929257, loss = 0.135026\n",
      "\n",
      "Dataset 2: NN classifier, alpha = 1.000 \n",
      "Train score = 0.963143, Test score = 0.930914, loss = 0.140907\n",
      "\n",
      "Dataset 2: NN classifier, alpha = 5.000 \n",
      "Train score = 0.962952, Test score = 0.932514, loss = 0.153408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for this_alpha in [0.01, 0.1, 1.0, 5.0]:\n",
    "    nnclf = MLPClassifier(solver='lbfgs', activation = 'tanh',\n",
    "                         alpha = this_alpha,\n",
    "                         hidden_layer_sizes = [10, 10],\n",
    "                         random_state = 0).fit(X_train, y_train)\n",
    "    train_score = nnclf.score(X_train, y_train)\n",
    "    test_score  = nnclf.score(X_test, y_test)\n",
    "    loss = nnclf.loss_\n",
    "    title = 'Dataset 2: NN classifier, alpha = {:.3f} '.format(this_alpha)\n",
    "    print(title)\n",
    "    title2 = \"Train score = %f, Test score = %f, loss = %f\\n\" % (train_score, test_score, loss)\n",
    "    print(title2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 2: NN classifier, 2 layers 10/10, identity activation function\n",
      "Train score = 0.939848, Test score = 0.916457, loss = 0.219484\n",
      "\n",
      "Dataset 2: NN classifier, 2 layers 10/10, logistic activation function\n",
      "Train score = 0.956133, Test score = 0.930514, loss = 0.162744\n",
      "\n",
      "Dataset 2: NN classifier, 2 layers 10/10, tanh activation function\n",
      "Train score = 0.963257, Test score = 0.929257, loss = 0.135026\n",
      "\n",
      "Dataset 2: NN classifier, 2 layers 10/10, relu activation function\n",
      "Train score = 0.923771, Test score = 0.910229, loss = 0.264048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The effect of different choices of activation function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "\n",
    "for this_activation in ['identity','logistic', 'tanh', 'relu']:\n",
    "    nnclf = MLPClassifier(solver='lbfgs', activation = this_activation,\n",
    "                         alpha = 0.1, hidden_layer_sizes = [10, 10],\n",
    "                         random_state = 0).fit(X_train, y_train)\n",
    "    train_score = nnclf.score(X_train, y_train)\n",
    "    test_score  = nnclf.score(X_test, y_test)    \n",
    "    loss = nnclf.loss_ \n",
    "    title = 'Dataset 2: NN classifier, 2 layers 10/10, {} activation function'.format(this_activation)\n",
    "    print(title)\n",
    "    title2 = \"Train score = %f, Test score = %f, loss = %f\\n\" % (train_score, test_score, loss)\n",
    "    print(title2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
      "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
      "       fit_params=None, iid='warn', n_jobs=-1,\n",
      "       param_grid={'solver': ['lbfgs', 'adam'], 'alpha': [0.001, 0.01, 0.1, 1], 'hidden_layer_sizes': array([ 5,  6,  7,  8,  9, 10, 11])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm, datasets\n",
    "from sklearn import neural_network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'solver': ['lbfgs','adam'], 'alpha':[0.001,0.01,0.1,1],\n",
    "              'hidden_layer_sizes':np.arange(5, 12),}\n",
    "clf_grid = GridSearchCV(neural_network.MLPClassifier(), parameters,n_jobs=-1)\n",
    "clf_grid.fit(X, y)\n",
    "print(clf_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Merve\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 83.09399001, 227.91917396,  79.14458807, 203.4513944 ,\n",
       "         74.35662484, 178.8643055 ,  67.59322143, 179.22334488,\n",
       "         75.88902871, 201.8463819 ,  78.76097306, 195.63333265,\n",
       "         77.33611743, 192.71480687,  65.64406212, 160.96274281,\n",
       "         66.38840612, 173.73391485,  67.33287772, 165.5757374 ,\n",
       "         67.0642643 , 181.20293617,  76.23805714, 191.79028289,\n",
       "         76.07548984, 193.28208232,  76.45057249, 194.08360442,\n",
       "         65.66367976, 157.79721165,  67.36113834, 166.33969506,\n",
       "         68.17429582, 166.75924095,  68.15102084, 178.51080275,\n",
       "         77.32282265, 188.49941468,  77.06484636, 188.4133122 ,\n",
       "         78.10938231, 174.32732503,  66.47683398, 147.52302869,\n",
       "         67.37975264, 126.79447953,  68.22914855, 143.86215893,\n",
       "         69.30128113, 149.40499663,  77.47906852, 136.87085891,\n",
       "         76.91557693, 112.29061182,  78.62533665,  79.84905974]),\n",
       " 'std_fit_time': array([ 2.67557669,  5.06661992,  6.38464686,  3.4322285 ,  7.33325315,\n",
       "         0.77624113,  0.36601777,  0.29670292,  0.32429811,  0.59074495,\n",
       "         1.80396573,  1.23629786,  0.09110394,  1.55884184,  0.20318463,\n",
       "        14.02281944,  0.82291863,  1.43387322,  0.65347427, 18.92708697,\n",
       "         0.49715282,  0.79751023,  0.06148395,  1.63945009,  0.91041746,\n",
       "         0.74844257,  0.58664836,  2.58605838,  1.08404416, 12.88569613,\n",
       "         0.38249397,  5.54785847,  0.67056349, 13.79124963,  0.06725945,\n",
       "         0.70714566,  0.56013276,  1.3461609 ,  0.17521348,  4.59190982,\n",
       "         0.13990529, 22.15302289,  0.11258143, 18.93304969,  0.23484804,\n",
       "        19.44939425,  0.55212695, 24.41547803,  0.06451267, 19.7723189 ,\n",
       "         0.43439774, 20.19169664,  0.32161858, 12.9759095 ,  0.22773614,\n",
       "        18.12663706]),\n",
       " 'mean_score_time': array([0.24962354, 0.19381372, 0.22233733, 0.1715409 , 0.18144536,\n",
       "        0.17054439, 0.16189988, 0.15857657, 0.18217913, 0.20976925,\n",
       "        0.18350951, 0.19547701, 0.18849889, 0.18384027, 0.16090242,\n",
       "        0.17686216, 0.1652259 , 0.1722068 , 0.16423074, 0.19680858,\n",
       "        0.15491947, 0.18483829, 0.17652845, 0.18117778, 0.17420204,\n",
       "        0.18816249, 0.17652845, 0.19680699, 0.16056935, 0.17420228,\n",
       "        0.15524928, 0.17951703, 0.1725378 , 0.17685795, 0.1632309 ,\n",
       "        0.17719237, 0.16588879, 0.1835084 , 0.17320355, 0.20744332,\n",
       "        0.18450594, 0.18118318, 0.18284281, 0.18217993, 0.17453424,\n",
       "        0.18317779, 0.15126093, 0.15325562, 0.1778566 , 0.18550181,\n",
       "        0.16988134, 0.18517272, 0.1728723 , 0.16422892, 0.16854787,\n",
       "        0.0831395 ]),\n",
       " 'std_score_time': array([0.02407984, 0.00577658, 0.01512724, 0.00710007, 0.02035343,\n",
       "        0.02171403, 0.01288288, 0.0024424 , 0.01726186, 0.028514  ,\n",
       "        0.01232268, 0.0138926 , 0.01553568, 0.01264998, 0.00964697,\n",
       "        0.01018161, 0.01323929, 0.01235713, 0.01385303, 0.023237  ,\n",
       "        0.00577344, 0.01123233, 0.01292699, 0.01529002, 0.01105596,\n",
       "        0.00329219, 0.00785273, 0.00729825, 0.00814364, 0.01600666,\n",
       "        0.00384881, 0.02198726, 0.0174091 , 0.01669398, 0.02209372,\n",
       "        0.00477242, 0.00124433, 0.00430723, 0.0172029 , 0.02055379,\n",
       "        0.00453384, 0.01343724, 0.02083161, 0.01385059, 0.01785989,\n",
       "        0.00384835, 0.00878335, 0.00692424, 0.01343751, 0.00354948,\n",
       "        0.01246608, 0.0061656 , 0.01377901, 0.01629378, 0.01077323,\n",
       "        0.00950554]),\n",
       " 'param_alpha': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_hidden_layer_sizes': masked_array(data=[5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 5, 5, 6,\n",
       "                    6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 5, 5, 6, 6, 7, 7,\n",
       "                    8, 8, 9, 9, 10, 10, 11, 11, 5, 5, 6, 6, 7, 7, 8, 8, 9,\n",
       "                    9, 10, 10, 11, 11],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['lbfgs', 'adam', 'lbfgs', 'adam', 'lbfgs', 'adam',\n",
       "                    'lbfgs', 'adam', 'lbfgs', 'adam', 'lbfgs', 'adam',\n",
       "                    'lbfgs', 'adam', 'lbfgs', 'adam', 'lbfgs', 'adam',\n",
       "                    'lbfgs', 'adam', 'lbfgs', 'adam', 'lbfgs', 'adam',\n",
       "                    'lbfgs', 'adam', 'lbfgs', 'adam', 'lbfgs', 'adam',\n",
       "                    'lbfgs', 'adam', 'lbfgs', 'adam', 'lbfgs', 'adam',\n",
       "                    'lbfgs', 'adam', 'lbfgs', 'adam', 'lbfgs', 'adam',\n",
       "                    'lbfgs', 'adam', 'lbfgs', 'adam', 'lbfgs', 'adam',\n",
       "                    'lbfgs', 'adam', 'lbfgs', 'adam', 'lbfgs', 'adam',\n",
       "                    'lbfgs', 'adam'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.001, 'hidden_layer_sizes': 5, 'solver': 'lbfgs'},\n",
       "  {'alpha': 0.001, 'hidden_layer_sizes': 5, 'solver': 'adam'},\n",
       "  {'alpha': 0.001, 'hidden_layer_sizes': 6, 'solver': 'lbfgs'},\n",
       "  {'alpha': 0.001, 'hidden_layer_sizes': 6, 'solver': 'adam'},\n",
       "  {'alpha': 0.001, 'hidden_layer_sizes': 7, 'solver': 'lbfgs'},\n",
       "  {'alpha': 0.001, 'hidden_layer_sizes': 7, 'solver': 'adam'},\n",
       "  {'alpha': 0.001, 'hidden_layer_sizes': 8, 'solver': 'lbfgs'},\n",
       "  {'alpha': 0.001, 'hidden_layer_sizes': 8, 'solver': 'adam'},\n",
       "  {'alpha': 0.001, 'hidden_layer_sizes': 9, 'solver': 'lbfgs'},\n",
       "  {'alpha': 0.001, 'hidden_layer_sizes': 9, 'solver': 'adam'},\n",
       "  {'alpha': 0.001, 'hidden_layer_sizes': 10, 'solver': 'lbfgs'},\n",
       "  {'alpha': 0.001, 'hidden_layer_sizes': 10, 'solver': 'adam'},\n",
       "  {'alpha': 0.001, 'hidden_layer_sizes': 11, 'solver': 'lbfgs'},\n",
       "  {'alpha': 0.001, 'hidden_layer_sizes': 11, 'solver': 'adam'},\n",
       "  {'alpha': 0.01, 'hidden_layer_sizes': 5, 'solver': 'lbfgs'},\n",
       "  {'alpha': 0.01, 'hidden_layer_sizes': 5, 'solver': 'adam'},\n",
       "  {'alpha': 0.01, 'hidden_layer_sizes': 6, 'solver': 'lbfgs'},\n",
       "  {'alpha': 0.01, 'hidden_layer_sizes': 6, 'solver': 'adam'},\n",
       "  {'alpha': 0.01, 'hidden_layer_sizes': 7, 'solver': 'lbfgs'},\n",
       "  {'alpha': 0.01, 'hidden_layer_sizes': 7, 'solver': 'adam'},\n",
       "  {'alpha': 0.01, 'hidden_layer_sizes': 8, 'solver': 'lbfgs'},\n",
       "  {'alpha': 0.01, 'hidden_layer_sizes': 8, 'solver': 'adam'},\n",
       "  {'alpha': 0.01, 'hidden_layer_sizes': 9, 'solver': 'lbfgs'},\n",
       "  {'alpha': 0.01, 'hidden_layer_sizes': 9, 'solver': 'adam'},\n",
       "  {'alpha': 0.01, 'hidden_layer_sizes': 10, 'solver': 'lbfgs'},\n",
       "  {'alpha': 0.01, 'hidden_layer_sizes': 10, 'solver': 'adam'},\n",
       "  {'alpha': 0.01, 'hidden_layer_sizes': 11, 'solver': 'lbfgs'},\n",
       "  {'alpha': 0.01, 'hidden_layer_sizes': 11, 'solver': 'adam'},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': 5, 'solver': 'lbfgs'},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': 5, 'solver': 'adam'},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': 6, 'solver': 'lbfgs'},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': 6, 'solver': 'adam'},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': 7, 'solver': 'lbfgs'},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': 7, 'solver': 'adam'},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': 8, 'solver': 'lbfgs'},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': 8, 'solver': 'adam'},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': 9, 'solver': 'lbfgs'},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': 9, 'solver': 'adam'},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': 10, 'solver': 'lbfgs'},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': 10, 'solver': 'adam'},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': 11, 'solver': 'lbfgs'},\n",
       "  {'alpha': 0.1, 'hidden_layer_sizes': 11, 'solver': 'adam'},\n",
       "  {'alpha': 1, 'hidden_layer_sizes': 5, 'solver': 'lbfgs'},\n",
       "  {'alpha': 1, 'hidden_layer_sizes': 5, 'solver': 'adam'},\n",
       "  {'alpha': 1, 'hidden_layer_sizes': 6, 'solver': 'lbfgs'},\n",
       "  {'alpha': 1, 'hidden_layer_sizes': 6, 'solver': 'adam'},\n",
       "  {'alpha': 1, 'hidden_layer_sizes': 7, 'solver': 'lbfgs'},\n",
       "  {'alpha': 1, 'hidden_layer_sizes': 7, 'solver': 'adam'},\n",
       "  {'alpha': 1, 'hidden_layer_sizes': 8, 'solver': 'lbfgs'},\n",
       "  {'alpha': 1, 'hidden_layer_sizes': 8, 'solver': 'adam'},\n",
       "  {'alpha': 1, 'hidden_layer_sizes': 9, 'solver': 'lbfgs'},\n",
       "  {'alpha': 1, 'hidden_layer_sizes': 9, 'solver': 'adam'},\n",
       "  {'alpha': 1, 'hidden_layer_sizes': 10, 'solver': 'lbfgs'},\n",
       "  {'alpha': 1, 'hidden_layer_sizes': 10, 'solver': 'adam'},\n",
       "  {'alpha': 1, 'hidden_layer_sizes': 11, 'solver': 'lbfgs'},\n",
       "  {'alpha': 1, 'hidden_layer_sizes': 11, 'solver': 'adam'}],\n",
       " 'split0_test_score': array([0.86394412, 0.8950977 , 0.87080048, 0.90872472, 0.89209805,\n",
       "        0.92136613, 0.89372643, 0.92389441, 0.9045252 , 0.92967947,\n",
       "        0.91540967, 0.92809393, 0.92102331, 0.92980802, 0.64899726,\n",
       "        0.89488344, 0.89724032, 0.90782482, 0.81277854, 0.91879499,\n",
       "        0.9064107 , 0.92697977, 0.92059479, 0.92830819, 0.92415153,\n",
       "        0.93452177, 0.90336819, 0.93482173, 0.90122557, 0.88198492,\n",
       "        0.70834762, 0.91211004, 0.9102674 , 0.91956634, 0.90833905,\n",
       "        0.92865101, 0.8978831 , 0.9321649 , 0.90281111, 0.93803565,\n",
       "        0.92136613, 0.93992115, 0.65692492, 0.8902554 , 0.87478574,\n",
       "        0.9017398 , 0.8672866 , 0.91172437, 0.90383956, 0.91742372,\n",
       "        0.91056736, 0.92059479, 0.92312307, 0.9255228 , 0.92787967,\n",
       "        0.92727974]),\n",
       " 'split1_test_score': array([0.80152574, 0.88976985, 0.85689796, 0.9018986 , 0.85801226,\n",
       "        0.91257018, 0.8877984 , 0.91505593, 0.890027  , 0.92362748,\n",
       "        0.92058458, 0.92662752, 0.92714182, 0.92954185, 0.7770111 ,\n",
       "        0.89131273, 0.78271118, 0.90584151, 0.89178417, 0.91925599,\n",
       "        0.90069858, 0.92075601, 0.90279861, 0.92525608, 0.93434192,\n",
       "        0.92212746, 0.91848455, 0.93074187, 0.68799554, 0.89379848,\n",
       "        0.86418377, 0.90451292, 0.88981271, 0.91981314, 0.92075601,\n",
       "        0.919856  , 0.91415592, 0.93142759, 0.90691296, 0.93378477,\n",
       "        0.91861312, 0.93648481, 0.81194017, 0.88436978, 0.80911156,\n",
       "        0.89636995, 0.90678438, 0.9057558 , 0.91578451, 0.91128445,\n",
       "        0.91089873, 0.91775597, 0.90648438, 0.92075601, 0.9240132 ,\n",
       "        0.92701324]),\n",
       " 'split2_test_score': array([0.8093095 , 0.8963182 , 0.85800009, 0.91286271, 0.90197591,\n",
       "        0.92246367, 0.92349235, 0.925764  , 0.90261883, 0.93163602,\n",
       "        0.91474862, 0.93395054, 0.91950624, 0.93317903, 0.90403326,\n",
       "        0.88933179, 0.81226694, 0.91256268, 0.87720201, 0.91693455,\n",
       "        0.90977669, 0.93142171, 0.89601817, 0.93377909, 0.92040633,\n",
       "        0.93827954, 0.9141057 , 0.93960825, 0.8753161 , 0.90189019,\n",
       "        0.87565899, 0.91513437, 0.9233209 , 0.92456388, 0.86494364,\n",
       "        0.93442201, 0.92829283, 0.9383224 , 0.92134928, 0.9375509 ,\n",
       "        0.92152072, 0.94445159, 0.79465089, 0.89430372, 0.89768977,\n",
       "        0.9064335 , 0.89083194, 0.91200549, 0.90729073, 0.91912048,\n",
       "        0.92134928, 0.92824997, 0.92915006, 0.92619262, 0.93317903,\n",
       "        0.93116455]),\n",
       " 'mean_test_score': array([0.82492857, 0.89372857, 0.8619    , 0.90782857, 0.88402857,\n",
       "        0.9188    , 0.90167143, 0.92157143, 0.89905714, 0.92831429,\n",
       "        0.91691429, 0.92955714, 0.92255714, 0.93084286, 0.77667143,\n",
       "        0.89184286, 0.83074286, 0.90874286, 0.86058571, 0.91832857,\n",
       "        0.90562857, 0.92638571, 0.90647143, 0.92911429, 0.9263    ,\n",
       "        0.93164286, 0.91198571, 0.93505714, 0.82151429, 0.89255714,\n",
       "        0.81605714, 0.91058571, 0.9078    , 0.92131429, 0.89801429,\n",
       "        0.92764286, 0.91344286, 0.93397143, 0.91035714, 0.93645714,\n",
       "        0.9205    , 0.94028571, 0.7545    , 0.88964286, 0.86052857,\n",
       "        0.90151429, 0.8883    , 0.90982857, 0.90897143, 0.91594286,\n",
       "        0.91427143, 0.9222    , 0.91958571, 0.92415714, 0.92835714,\n",
       "        0.92848571]),\n",
       " 'std_test_score': array([0.02777291, 0.00284321, 0.00631019, 0.00452059, 0.01883293,\n",
       "        0.00442783, 0.01561723, 0.0046699 , 0.00643246, 0.00340894,\n",
       "        0.00260926, 0.00316353, 0.00330045, 0.00165537, 0.10411866,\n",
       "        0.00229725, 0.04854809, 0.00281959, 0.03432778, 0.00100346,\n",
       "        0.00374706, 0.00437435, 0.01036406, 0.00352579, 0.0058884 ,\n",
       "        0.00690101, 0.00635081, 0.00362341, 0.09500169, 0.00817359,\n",
       "        0.07631259, 0.00446805, 0.01379011, 0.00229985, 0.02392593,\n",
       "        0.00598897, 0.012425  , 0.00309106, 0.0079504 , 0.00189997,\n",
       "        0.0013357 , 0.00326253, 0.06936196, 0.00407847, 0.0375401 ,\n",
       "        0.0041114 , 0.01622438, 0.00288214, 0.00501933, 0.00336601,\n",
       "        0.00500625, 0.00443188, 0.00958513, 0.00242043, 0.00375703,\n",
       "        0.0018972 ]),\n",
       " 'rank_test_score': array([52, 42, 48, 34, 47, 22, 38, 18, 40, 11, 24,  7, 16,  6, 55, 44, 51,\n",
       "        33, 49, 23, 37, 13, 36,  8, 14,  5, 28,  3, 53, 43, 54, 29, 35, 19,\n",
       "        41, 12, 27,  4, 30,  2, 20,  1, 56, 45, 50, 39, 46, 31, 32, 25, 26,\n",
       "        17, 21, 15, 10,  9]),\n",
       " 'split0_train_score': array([0.87182839, 0.91530945, 0.88044317, 0.93123178, 0.90600891,\n",
       "        0.94428253, 0.90303017, 0.95077576, 0.92263844, 0.95765472,\n",
       "        0.93343905, 0.96376221, 0.94126093, 0.96554089, 0.65765901,\n",
       "        0.91057346, 0.90744471, 0.92833876, 0.82097548, 0.9390108 ,\n",
       "        0.91995971, 0.95129007, 0.9347677 , 0.95829762, 0.94173238,\n",
       "        0.96142637, 0.91288788, 0.96691239, 0.91063775, 0.89497257,\n",
       "        0.71033345, 0.92308846, 0.92583148, 0.93258186, 0.91903823,\n",
       "        0.94207526, 0.90965198, 0.94933996, 0.91539517, 0.95583319,\n",
       "        0.93830362, 0.95831905, 0.66612378, 0.89315104, 0.88438625,\n",
       "        0.90495885, 0.87264272, 0.91595234, 0.91389508, 0.92242414,\n",
       "        0.92428853, 0.92662438, 0.93680353, 0.93181039, 0.94327533,\n",
       "        0.93281759]),\n",
       " 'split1_train_score': array([0.82000129, 0.91507918, 0.8741509 , 0.92847194, 0.87447233,\n",
       "        0.94212184, 0.9077078 , 0.9465361 , 0.90837208, 0.95650031,\n",
       "        0.94278612, 0.9644074 , 0.95037178, 0.96877879, 0.79514432,\n",
       "        0.91255062, 0.79512289, 0.93267191, 0.9104935 , 0.94597896,\n",
       "        0.9236934 , 0.94715752, 0.92212913, 0.95782887, 0.95669317,\n",
       "        0.95971457, 0.94137185, 0.96524311, 0.70722352, 0.9116292 ,\n",
       "        0.8818437 , 0.92362912, 0.9084578 , 0.93890758, 0.93837187,\n",
       "        0.94263612, 0.93438618, 0.95110035, 0.92555767, 0.95420747,\n",
       "        0.94162899, 0.95911458, 0.82660124, 0.89596503, 0.82471554,\n",
       "        0.90916493, 0.92656481, 0.92013628, 0.93485761, 0.92442197,\n",
       "        0.93102192, 0.93102192, 0.92506482, 0.9322862 , 0.94615038,\n",
       "        0.93785759]),\n",
       " 'split2_train_score': array([0.80991665, 0.90871885, 0.85827851, 0.92425379, 0.9096188 ,\n",
       "        0.93676745, 0.9346247 , 0.94743834, 0.90756176, 0.95598791,\n",
       "        0.91992543, 0.95701643, 0.9276179 , 0.9637661 , 0.91049733,\n",
       "        0.8959052 , 0.80843815, 0.92611798, 0.87887034, 0.93186055,\n",
       "        0.91602563, 0.94756691, 0.90121922, 0.95875206, 0.93331762,\n",
       "        0.96121622, 0.92146821, 0.96608027, 0.88326298, 0.90730463,\n",
       "        0.8814845 , 0.92253959, 0.93436757, 0.93505325, 0.86530673,\n",
       "        0.94270286, 0.93708886, 0.9474812 , 0.93483897, 0.94938824,\n",
       "        0.92924639, 0.95879492, 0.79324605, 0.89311963, 0.90040498,\n",
       "        0.90511903, 0.8959052 , 0.91129015, 0.9164756 , 0.91851122,\n",
       "        0.93239624, 0.92684651, 0.94302428, 0.92808931, 0.94424564,\n",
       "        0.92954638]),\n",
       " 'mean_train_score': array([0.83391544, 0.91303582, 0.87095753, 0.92798584, 0.89670001,\n",
       "        0.94105727, 0.91512089, 0.94825007, 0.91285743, 0.95671432,\n",
       "        0.9320502 , 0.96172868, 0.93975021, 0.96602859, 0.78776689,\n",
       "        0.9063431 , 0.83700192, 0.92904288, 0.87011311, 0.9389501 ,\n",
       "        0.91989291, 0.9486715 , 0.91937202, 0.95829285, 0.94391439,\n",
       "        0.96078572, 0.92524265, 0.96607859, 0.83370808, 0.90463547,\n",
       "        0.82455388, 0.92308572, 0.92288561, 0.93551423, 0.90757228,\n",
       "        0.94247142, 0.92704234, 0.94930717, 0.92526394, 0.95314297,\n",
       "        0.936393  , 0.95874285, 0.76199036, 0.89407857, 0.86983559,\n",
       "        0.90641427, 0.89837091, 0.91579292, 0.92174276, 0.92178577,\n",
       "        0.92923556, 0.92816427, 0.93496421, 0.93072863, 0.94455712,\n",
       "        0.93340719]),\n",
       " 'std_train_score': array([0.02712279, 0.00305401, 0.00932617, 0.00286942, 0.01578629,\n",
       "        0.00315902, 0.01392286, 0.00182352, 0.00692412, 0.00069709,\n",
       "        0.00938437, 0.00334246, 0.00935045, 0.00207528, 0.10335255,\n",
       "        0.00742471, 0.05010632, 0.00272156, 0.03706648, 0.00576398,\n",
       "        0.00313071, 0.00185914, 0.01383417, 0.00037691, 0.00966695,\n",
       "        0.00076226, 0.01193088, 0.00068149, 0.09013362, 0.00705711,\n",
       "        0.08076618, 0.0004448 , 0.01078077, 0.00260295, 0.03091094,\n",
       "        0.00028145, 0.01234624, 0.00147769, 0.00794062, 0.00273669,\n",
       "        0.00523259, 0.00032685, 0.06914209, 0.00133399, 0.03256802,\n",
       "        0.00194611, 0.02208254, 0.00361318, 0.00933324, 0.00245491,\n",
       "        0.00354279, 0.0020227 , 0.00744638, 0.00187636, 0.00119422,\n",
       "        0.00341855])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=11, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9402857142857143"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1, 'hidden_layer_sizes': 11, 'solver': 'adam'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_grid.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
